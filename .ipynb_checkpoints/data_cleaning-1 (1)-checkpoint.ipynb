{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c94f641-0910-4627-8f93-174fc1848587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jahr</th>\n",
       "      <th>Krankenkasse</th>\n",
       "      <th>Quartal</th>\n",
       "      <th>Mitglieder</th>\n",
       "      <th>Versicherte</th>\n",
       "      <th>Zusatzbeitrag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>AOK Baden-Württemberg</td>\n",
       "      <td>1</td>\n",
       "      <td>3539685</td>\n",
       "      <td>4615478</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>AOK Bayern</td>\n",
       "      <td>1</td>\n",
       "      <td>3627408</td>\n",
       "      <td>4603276</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>AOK Bremen/Bremerhaven</td>\n",
       "      <td>1</td>\n",
       "      <td>207431</td>\n",
       "      <td>284469</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025</td>\n",
       "      <td>AOK Hessen</td>\n",
       "      <td>1</td>\n",
       "      <td>1281555</td>\n",
       "      <td>1730176</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>AOK Niedersachsen</td>\n",
       "      <td>1</td>\n",
       "      <td>2324317</td>\n",
       "      <td>3058918</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Jahr            Krankenkasse  Quartal  Mitglieder  Versicherte  \\\n",
       "0  2025   AOK Baden-Württemberg        1     3539685      4615478   \n",
       "1  2025              AOK Bayern        1     3627408      4603276   \n",
       "2  2025  AOK Bremen/Bremerhaven        1      207431       284469   \n",
       "3  2025              AOK Hessen        1     1281555      1730176   \n",
       "4  2025       AOK Niedersachsen        1     2324317      3058918   \n",
       "\n",
       "   Zusatzbeitrag  \n",
       "0           2.60  \n",
       "1           2.69  \n",
       "2           2.49  \n",
       "3           2.49  \n",
       "4           2.70  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct way to load the file from your local path\n",
    "zusatz_df = pd.read_excel(r\"C:\\Users\\Vanshika\\OneDrive\\Documents\\DS Project\\Topic 1\\Topic 1\\Zusatzbeitrag_je Kasse je Quartal.xlsx\")\n",
    "zusatz_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb5ff7ad-95ed-42ca-aa8c-629b20d342d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "zusatz_df = pd.read_excel(r\"C:\\Users\\Vanshika\\OneDrive\\Documents\\DS Project\\Topic 1\\Topic 1\\Zusatzbeitrag_je Kasse je Quartal.xlsx\")\n",
    "markt_df = pd.read_excel(r\"C:\\Users\\Vanshika\\OneDrive\\Documents\\DS Project\\Topic 1\\Topic 1\\Marktanteile je Kasse.xlsx\", sheet_name=\"data\")\n",
    "morbidity_df = pd.read_excel(r\"C:\\Users\\Vanshika\\OneDrive\\Documents\\DS Project\\Topic 1\\Topic 1\\Morbidity_Region.xlsx\")\n",
    "\n",
    "# Strip whitespace, lowercase, and normalize fund names\n",
    "def clean_name(name):\n",
    "    return name.strip().lower().replace(\"-\", \"\").replace(\"/\", \"\")\n",
    "\n",
    "zusatz_df[\"kasse_clean\"] = zusatz_df[\"Krankenkasse\"].apply(clean_name)\n",
    "markt_df[\"kasse_clean\"] = markt_df[\"Krankenkasse\"].apply(clean_name)\n",
    "\n",
    "# print(\"zusatz_df columns:\", zusatz_df.columns.tolist())\n",
    "# print(\"markt_df columns:\", markt_df.columns.tolist())\n",
    "\n",
    "zusatz_df.columns = zusatz_df.columns.str.strip().str.lower()\n",
    "markt_df.columns = markt_df.columns.str.strip().str.lower()\n",
    "\n",
    "# Assuming both datasets have 'jahr' and 'quartal'\n",
    "merged_df = pd.merge(\n",
    "    zusatz_df,\n",
    "    markt_df,\n",
    "    on=[\"jahr\", \"kasse_clean\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "merged_df = merged_df.sort_values(by=[\"kasse_clean\", \"jahr\", \"quartal\"])\n",
    "\n",
    "merged_df[\"insured_lag\"] = merged_df.groupby(\"kasse_clean\")[\"versicherte\"].shift(1)\n",
    "merged_df[\"churn_rate\"] = (\n",
    "    (merged_df[\"insured_lag\"] - merged_df[\"versicherte\"]) / merged_df[\"insured_lag\"]\n",
    ")\n",
    "\n",
    "merged_df[\"zusatzbeitrag_lag\"] = merged_df.groupby(\"kasse_clean\")[\"zusatzbeitrag\"].shift(1)\n",
    "merged_df[\"treatment_flag\"] = merged_df[\"zusatzbeitrag\"] > merged_df[\"zusatzbeitrag_lag\"]\n",
    "\n",
    "# Drop rows with missing insured_lag or zusatzbeitrag_lag for causal analysis\n",
    "panel_df = merged_df.dropna(subset=[\"insured_lag\", \"zusatzbeitrag_lag\"])\n",
    "\n",
    "# Save for further steps\n",
    "panel_df.to_csv(\"merged_panel_data.csv\", index=False)\n",
    "\n",
    "morbidity_df[\"kasse_clean\"] = morbidity_df[\"Krankenkasse\"].str.strip().str.lower()\n",
    "merged_df[\"kasse_clean\"] = merged_df[\"kasse_clean\"].str.strip().str.lower()\n",
    "\n",
    "morbidity_df.columns = morbidity_df.columns.str.strip().str.lower()\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    merged_df,\n",
    "    morbidity_df[[\"jahr\", \"kasse_clean\", \"risikofaktor\"]],\n",
    "    on=[\"jahr\", \"kasse_clean\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "merged_df.rename(columns={\"risikofaktor\": \"morbidity_index\"}, inplace=True)\n",
    "\n",
    "merged_df.to_csv(\"merged_panel_morbidity_data.csv\", index=False)\n",
    "\n",
    "# kunden_2023 = pd.read_excel(r\"C:\\Users\\Vanshika\\OneDrive\\Documents\\DS Project\\Topic 1\\Topic 1\\Kundenmonitor_GKV_2023.xlsx\")\n",
    "# kunden_2024 = pd.read_excel(r\"C:\\Users\\Vanshika\\OneDrive\\Documents\\DS Project\\Topic 1\\Topic 1\\Kundenmonitor_GKV_2024.xlsx\")\n",
    "\n",
    "# print(\"Kundenmonitor 2023 columns:\", kunden_2023.columns.tolist())\n",
    "# print(\"Kundenmonitor 2024 columns:\", kunden_2024.columns.tolist())\n",
    "\n",
    "# for df in [kunden_2023, kunden_2024]:\n",
    "#     df.columns = df.columns.str.lower()\n",
    "#     df[\"kasse_clean\"] = df[\"krankenkasse\"].apply(clean_name)\n",
    "\n",
    "# kunden_df = pd.concat([kunden_2023, kunden_2024], ignore_index=True)\n",
    "\n",
    "# kunden_df.columns = kunden_df.columns.str.lower()\n",
    "# kunden_df[\"kasse_clean\"] = kunden_df[\"krankenkasse\"].apply(clean_name)\n",
    "\n",
    "# # Join on 'kasse_clean' and 'jahr' if year is present\n",
    "# merged_df = pd.merge(\n",
    "#     merged_df,\n",
    "#     kunden_df[[\"kasse_clean\", \"zufriedenheit\"]],  # adjust with actual column names\n",
    "#     on=\"kasse_clean\",\n",
    "#     how=\"left\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb7a86a9-726f-4026-ab2d-9c5135bf1958",
   "metadata": {},
   "outputs": [],
   "source": [
    "kunden_2023 = pd.read_excel(r\"C:\\Users\\Vanshika\\OneDrive\\Documents\\DS Project\\Topic 1\\Topic 1\\Kundenmonitor_GKV_2023.xlsx\")\n",
    "kunden_2024 = pd.read_excel(r\"C:\\Users\\Vanshika\\OneDrive\\Documents\\DS Project\\Topic 1\\Topic 1\\Kundenmonitor_GKV_2024.xlsx\")\n",
    "\n",
    "kunden_2023.columns = kunden_2023.columns.str.strip()\n",
    "kunden_2024.columns = kunden_2024.columns.str.strip()\n",
    "\n",
    "# Use the correct column name for fund name\n",
    "fund_col = 'Mitglied/Kunde einer Krankenkasse/Krankenversicherung'\n",
    "\n",
    "# Apply fund name cleaning\n",
    "kunden_2023[\"kasse_clean\"] = kunden_2023[fund_col].str.lower().str.strip()\n",
    "kunden_2023[\"jahr\"] = 2023\n",
    "\n",
    "kunden_2024[\"kasse_clean\"] = kunden_2024[fund_col].str.lower().str.strip()\n",
    "kunden_2024[\"jahr\"] = 2024\n",
    "\n",
    "kunden_df = pd.concat([kunden_2023, kunden_2024], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60b16826-db02-48c3-8063-1f13e1ac9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(\n",
    "    merged_df,\n",
    "    kunden_df,\n",
    "    on=[\"jahr\", \"kasse_clean\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "merged_df.to_csv(\"merged_panel_kunden_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0549817-17ac-472e-9171-654d95f76cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.sort_values(by=[\"kasse_clean\", \"jahr\", \"quartal\"])\n",
    "\n",
    "merged_df[\"insured_lag\"] = merged_df.groupby(\"kasse_clean\")[\"versicherte\"].shift(1)\n",
    "merged_df[\"churn_rate\"] = (merged_df[\"insured_lag\"] - merged_df[\"versicherte\"]) / merged_df[\"insured_lag\"]\n",
    "merged_df[\"zusatzbeitrag_lag\"] = merged_df.groupby(\"kasse_clean\")[\"zusatzbeitrag\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc99e3f9-3c4f-4cdc-82d4-24006acac3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"treatment_flag\"] = merged_df[\"zusatzbeitrag\"] > merged_df[\"zusatzbeitrag_lag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e35c4eaf-c7dc-4ba9-9302-cc413832628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_avg = merged_df.groupby([\"jahr\", \"quartal\"])[\"zusatzbeitrag\"].mean().reset_index()\n",
    "merged_df = pd.merge(merged_df, period_avg, on=[\"jahr\", \"quartal\"], how=\"left\", suffixes=(\"\", \"_avg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33cbcc2e-57c1-4f90-847f-de36bfc19dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing core variables\n",
    "merged_df = merged_df.dropna(subset=[\"insured_lag\", \"zusatzbeitrag_lag\", \"churn_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffda1d4b-cb8c-4d55-a8c8-aaa2110cfe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"merged_panel_clean_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0d15a-778c-4dc8-9ab4-d48abea720f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install linearmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\Vanshika\\OneDrive\\Documents\\DS Project\\merged_panel_clean_data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79aa1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load cleaned panel\n",
    "# df = pd.read_csv(\"merged_panel_clean_data.csv\")\n",
    "\n",
    "# Create a combined time identifier\n",
    "df[\"zeit\"] = df[\"jahr\"].astype(str) + \"Q\" + df[\"quartal\"].astype(str)\n",
    "df[\"zeit\"] = df[\"zeit\"].astype(\"category\")\n",
    "\n",
    "# Optional: define post-treatment indicator (cumulative)\n",
    "df[\"post\"] = df.groupby(\"kasse_clean\")[\"treatment_flag\"].transform(lambda x: x.cumsum() > 0)\n",
    "\n",
    "# print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb53417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.formula.api as smf\n",
    "\n",
    "df[\"treatment_flag\"] = df[\"treatment_flag\"].astype(int)\n",
    "df[\"post\"] = df[\"post\"].astype(int)\n",
    "df[\"churn_rate\"] = pd.to_numeric(df[\"churn_rate\"], errors=\"coerce\")\n",
    "df[\"morbidity_index\"] = pd.to_numeric(df[\"morbidity_index\"], errors=\"coerce\")\n",
    "df[\"zusatzbeitrag_lag\"] = pd.to_numeric(df[\"zusatzbeitrag_lag\"], errors=\"coerce\")\n",
    "\n",
    "df_model = df.dropna(subset=[\"churn_rate\", \"treatment_flag\", \"post\", \"morbidity_index\", \"zusatzbeitrag_lag\"])\n",
    "\n",
    "# # Fit OLS model with interaction\n",
    "# did_model = smf.ols(\n",
    "#     formula=\"churn_rate ~ treatment_flag * post + morbidity_index + zusatzbeitrag_lag\",\n",
    "#     data=df\n",
    "# ).fit()\n",
    "\n",
    "# # Show results\n",
    "# print(did_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44730043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "did_model = smf.ols(\n",
    "    formula=\"churn_rate ~ treatment_flag * post + morbidity_index + zusatzbeitrag_lag\",\n",
    "    data=df_model\n",
    ").fit()\n",
    "\n",
    "print(did_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd1529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df[\"zeit\"].unique()[:10])\n",
    "# print(df[\"zeit\"].dtype)\n",
    "\n",
    "# Convert 'zeit' to datetime (quarter start)\n",
    "df[\"zeit_dt\"] = pd.PeriodIndex(df[\"zeit\"].astype(str), freq=\"Q\").to_timestamp()\n",
    "\n",
    "df[\"kasse_clean\"] = df[\"kasse_clean\"].astype(str)\n",
    "df_panel = df.set_index([\"kasse_clean\", \"zeit_dt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linearmodels.panel import PanelOLS\n",
    "\n",
    "fe_model = PanelOLS.from_formula(\n",
    "    formula=\"churn_rate ~ treatment_flag + morbidity_index + zusatzbeitrag_lag + EntityEffects + TimeEffects\",\n",
    "    data=df_panel\n",
    ")\n",
    "\n",
    "fe_results = fe_model.fit()\n",
    "print(fe_results.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726b2252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "940d5519-8b4f-4f88-a188-fddb8dddcd89",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'merged_panel_clean_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load your processed data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmerged_panel_clean_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Create combined time period\u001b[39;00m\n\u001b[32m     10\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mzeit\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mjahr\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[33mQ\u001b[39m\u001b[33m\"\u001b[39m + df[\u001b[33m\"\u001b[39m\u001b[33mquartal\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'merged_panel_clean_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your processed data\n",
    "df = pd.read_csv(\"merged_panel_clean_data.csv\", low_memory=False)\n",
    "\n",
    "\n",
    "# Create combined time period\n",
    "df[\"zeit\"] = df[\"jahr\"].astype(str) + \"Q\" + df[\"quartal\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf19d9-72f2-4563-ad95-2f491a204679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
