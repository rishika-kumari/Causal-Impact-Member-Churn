{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "880dea44-6d59-4504-a163-f1ae22dad296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in target:\n",
      "churn_rate\n",
      "0    15196\n",
      "1        6\n",
      "Name: count, dtype: int64\n",
      "Any NaNs in X_train? zusatzbeitrag              False\n",
      "zusatzbeitrag_avg          False\n",
      "morbidity_index            False\n",
      "marktanteil versicherte    False\n",
      "insured_lag                False\n",
      "dtype: bool\n",
      "Any NaNs in X_test? zusatzbeitrag              False\n",
      "zusatzbeitrag_avg          False\n",
      "morbidity_index            False\n",
      "marktanteil versicherte    False\n",
      "insured_lag                False\n",
      "dtype: bool\n",
      "Any NaNs in X_train_scaled? False\n",
      "Any NaNs in X_test_scaled? False\n",
      "Class weights: {0: np.float64(0.5002056597564989), 1: np.float64(1216.1)}\n",
      "Epoch 1/50\n",
      "304/304 - 1s - 2ms/step - accuracy: 0.9796 - loss: 2.5013 - val_accuracy: 1.0000 - val_loss: 0.0346\n",
      "Epoch 2/50\n",
      "304/304 - 0s - 534us/step - accuracy: 0.9995 - loss: 2.9719 - val_accuracy: 1.0000 - val_loss: 0.0456\n",
      "Epoch 3/50\n",
      "304/304 - 0s - 528us/step - accuracy: 0.9988 - loss: 1.9863 - val_accuracy: 1.0000 - val_loss: 0.0802\n",
      "Epoch 4/50\n",
      "304/304 - 0s - 554us/step - accuracy: 0.9763 - loss: 1.6575 - val_accuracy: 0.9955 - val_loss: 0.1637\n",
      "Epoch 5/50\n",
      "304/304 - 0s - 542us/step - accuracy: 0.9106 - loss: 0.7754 - val_accuracy: 0.9112 - val_loss: 0.2706\n",
      "Epoch 6/50\n",
      "304/304 - 0s - 544us/step - accuracy: 0.8469 - loss: 0.8727 - val_accuracy: 0.9264 - val_loss: 0.2737\n",
      "Epoch 7/50\n",
      "304/304 - 0s - 581us/step - accuracy: 0.7708 - loss: 0.8104 - val_accuracy: 0.7781 - val_loss: 0.4197\n",
      "Epoch 8/50\n",
      "304/304 - 0s - 577us/step - accuracy: 0.7471 - loss: 0.5074 - val_accuracy: 0.7567 - val_loss: 0.4426\n",
      "Epoch 9/50\n",
      "304/304 - 0s - 572us/step - accuracy: 0.7607 - loss: 0.3942 - val_accuracy: 0.7534 - val_loss: 0.4503\n",
      "Epoch 10/50\n",
      "304/304 - 0s - 567us/step - accuracy: 0.7621 - loss: 0.3554 - val_accuracy: 0.7781 - val_loss: 0.3940\n",
      "Epoch 11/50\n",
      "304/304 - 0s - 574us/step - accuracy: 0.8247 - loss: 0.4247 - val_accuracy: 0.9560 - val_loss: 0.1427\n",
      "Epoch 12/50\n",
      "304/304 - 0s - 569us/step - accuracy: 0.8816 - loss: 1.1943 - val_accuracy: 0.9026 - val_loss: 0.2076\n",
      "Epoch 13/50\n",
      "304/304 - 0s - 563us/step - accuracy: 0.8336 - loss: 0.4903 - val_accuracy: 0.8492 - val_loss: 0.2817\n",
      "Epoch 14/50\n",
      "304/304 - 0s - 577us/step - accuracy: 0.8270 - loss: 0.5374 - val_accuracy: 0.7509 - val_loss: 0.4167\n",
      "Epoch 15/50\n",
      "304/304 - 0s - 580us/step - accuracy: 0.7914 - loss: 0.6781 - val_accuracy: 0.7809 - val_loss: 0.3840\n",
      "Epoch 16/50\n",
      "304/304 - 0s - 566us/step - accuracy: 0.7799 - loss: 0.4394 - val_accuracy: 0.7345 - val_loss: 0.4741\n",
      "Epoch 17/50\n",
      "304/304 - 0s - 575us/step - accuracy: 0.7539 - loss: 0.5224 - val_accuracy: 0.7924 - val_loss: 0.3838\n",
      "Epoch 18/50\n",
      "304/304 - 0s - 564us/step - accuracy: 0.7732 - loss: 0.4015 - val_accuracy: 0.8031 - val_loss: 0.3428\n",
      "Epoch 19/50\n",
      "304/304 - 0s - 545us/step - accuracy: 0.8269 - loss: 0.3093 - val_accuracy: 0.8492 - val_loss: 0.2940\n",
      "Epoch 20/50\n",
      "304/304 - 0s - 533us/step - accuracy: 0.8124 - loss: 0.3099 - val_accuracy: 0.8212 - val_loss: 0.3262\n",
      "Epoch 21/50\n",
      "304/304 - 0s - 537us/step - accuracy: 0.7872 - loss: 0.3430 - val_accuracy: 0.8171 - val_loss: 0.3305\n",
      "Epoch 22/50\n",
      "304/304 - 0s - 541us/step - accuracy: 0.8196 - loss: 0.2441 - val_accuracy: 0.8709 - val_loss: 0.2729\n",
      "Epoch 23/50\n",
      "304/304 - 0s - 533us/step - accuracy: 0.8593 - loss: 0.3657 - val_accuracy: 0.8903 - val_loss: 0.2331\n",
      "Epoch 24/50\n",
      "304/304 - 0s - 536us/step - accuracy: 0.8457 - loss: 0.2610 - val_accuracy: 0.8907 - val_loss: 0.2075\n",
      "Epoch 25/50\n",
      "304/304 - 0s - 534us/step - accuracy: 0.8633 - loss: 0.3709 - val_accuracy: 0.8607 - val_loss: 0.3090\n",
      "Epoch 26/50\n",
      "304/304 - 0s - 533us/step - accuracy: 0.8412 - loss: 0.2892 - val_accuracy: 0.8631 - val_loss: 0.2791\n",
      "Epoch 27/50\n",
      "304/304 - 0s - 533us/step - accuracy: 0.8508 - loss: 0.2803 - val_accuracy: 0.9137 - val_loss: 0.2001\n",
      "Epoch 28/50\n",
      "304/304 - 0s - 537us/step - accuracy: 0.8809 - loss: 0.2304 - val_accuracy: 0.9182 - val_loss: 0.1846\n",
      "Epoch 29/50\n",
      "304/304 - 0s - 535us/step - accuracy: 0.8872 - loss: 0.2855 - val_accuracy: 0.8734 - val_loss: 0.2460\n",
      "Epoch 30/50\n",
      "304/304 - 0s - 530us/step - accuracy: 0.8662 - loss: 0.2286 - val_accuracy: 0.8742 - val_loss: 0.2378\n",
      "Epoch 31/50\n",
      "304/304 - 0s - 534us/step - accuracy: 0.8550 - loss: 0.3226 - val_accuracy: 0.8886 - val_loss: 0.2322\n",
      "Epoch 32/50\n",
      "304/304 - 0s - 533us/step - accuracy: 0.8871 - loss: 0.2652 - val_accuracy: 0.8496 - val_loss: 0.3019\n",
      "Epoch 33/50\n",
      "304/304 - 0s - 532us/step - accuracy: 0.8670 - loss: 0.1682 - val_accuracy: 0.9260 - val_loss: 0.1670\n",
      "Epoch 34/50\n",
      "304/304 - 0s - 531us/step - accuracy: 0.9052 - loss: 0.2514 - val_accuracy: 0.8931 - val_loss: 0.2231\n",
      "Epoch 35/50\n",
      "304/304 - 0s - 529us/step - accuracy: 0.8958 - loss: 0.2850 - val_accuracy: 0.8574 - val_loss: 0.2691\n",
      "Epoch 36/50\n",
      "304/304 - 0s - 537us/step - accuracy: 0.8862 - loss: 0.1380 - val_accuracy: 0.9281 - val_loss: 0.1679\n",
      "Epoch 37/50\n",
      "304/304 - 0s - 535us/step - accuracy: 0.9273 - loss: 0.1643 - val_accuracy: 0.9129 - val_loss: 0.1975\n",
      "Epoch 38/50\n",
      "304/304 - 0s - 533us/step - accuracy: 0.9160 - loss: 0.1530 - val_accuracy: 0.9359 - val_loss: 0.1568\n",
      "Epoch 39/50\n",
      "304/304 - 0s - 532us/step - accuracy: 0.9475 - loss: 0.0798 - val_accuracy: 0.9729 - val_loss: 0.0970\n",
      "Epoch 40/50\n",
      "304/304 - 0s - 532us/step - accuracy: 0.9649 - loss: 0.0872 - val_accuracy: 0.9688 - val_loss: 0.1182\n",
      "Epoch 41/50\n",
      "304/304 - 0s - 531us/step - accuracy: 0.9543 - loss: 0.1709 - val_accuracy: 0.9671 - val_loss: 0.1149\n",
      "Epoch 42/50\n",
      "304/304 - 0s - 531us/step - accuracy: 0.9542 - loss: 0.1101 - val_accuracy: 0.9638 - val_loss: 0.1345\n",
      "Epoch 43/50\n",
      "304/304 - 0s - 531us/step - accuracy: 0.9396 - loss: 0.1297 - val_accuracy: 0.9684 - val_loss: 0.1277\n",
      "Epoch 44/50\n",
      "304/304 - 0s - 538us/step - accuracy: 0.9490 - loss: 0.1062 - val_accuracy: 0.9716 - val_loss: 0.1070\n",
      "Epoch 45/50\n",
      "304/304 - 0s - 531us/step - accuracy: 0.9643 - loss: 0.0922 - val_accuracy: 0.9700 - val_loss: 0.1027\n",
      "Epoch 46/50\n",
      "304/304 - 0s - 529us/step - accuracy: 0.9472 - loss: 0.1222 - val_accuracy: 0.9634 - val_loss: 0.1436\n",
      "Epoch 47/50\n",
      "304/304 - 0s - 594us/step - accuracy: 0.9582 - loss: 0.1878 - val_accuracy: 0.9478 - val_loss: 0.1718\n",
      "Epoch 48/50\n",
      "304/304 - 0s - 529us/step - accuracy: 0.9366 - loss: 0.1164 - val_accuracy: 0.9675 - val_loss: 0.1205\n",
      "Epoch 49/50\n",
      "304/304 - 0s - 533us/step - accuracy: 0.9674 - loss: 0.0846 - val_accuracy: 0.9363 - val_loss: 0.1631\n",
      "Epoch 50/50\n",
      "304/304 - 0s - 534us/step - accuracy: 0.9505 - loss: 0.3701 - val_accuracy: 0.9441 - val_loss: 0.1606\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step\n",
      "Any NaNs in predicted probabilities? False\n",
      "Best threshold by F1 score on test set: 0.9955\n",
      "F1 score at best threshold: 0.2500\n",
      "ROC-AUC: 0.9980263157894737\n",
      "F1 Score: 0.25\n",
      "Brier Score: 0.03943045160149222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, brier_score_loss, precision_recall_curve\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "\n",
    "def run_predictive_model(data_path):\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(data_path, low_memory=False)\n",
    "    df = df.loc[:, ~df.columns.str.contains(\"Unnamed\")]\n",
    "    df[\"morbidity_index\"] = pd.to_numeric(df[\"morbidity_index\"], errors=\"coerce\")\n",
    "    \n",
    "    # Drop rows with missing values in important columns including features and target\n",
    "    feature_cols = [\"zusatzbeitrag\", \"zusatzbeitrag_avg\", \"morbidity_index\", \"marktanteil versicherte\", \"insured_lag\"]\n",
    "    df_subset = df.dropna(subset=feature_cols + [\"churn_rate\", \"treatment_flag\"])\n",
    "    \n",
    "    # Extract features and target\n",
    "    X = df_subset[feature_cols]\n",
    "    y = df_subset[\"churn_rate\"]\n",
    "    \n",
    "    # Binarize target: churn if churn_rate > 0.05\n",
    "    y_binary = (y > 0.05).astype(int)\n",
    "    \n",
    "    # Check class distribution\n",
    "    print(\"Class distribution in target:\")\n",
    "    print(y_binary.value_counts())\n",
    "    \n",
    "    # Split train/test data (stratify to maintain class balance)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
    "    )\n",
    "    \n",
    "    # Confirm no NaNs in train/test splits\n",
    "    print(\"Any NaNs in X_train?\", np.isnan(X_train).any())\n",
    "    print(\"Any NaNs in X_test?\", np.isnan(X_test).any())\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Check for NaNs after scaling (should not be any)\n",
    "    print(\"Any NaNs in X_train_scaled?\", np.isnan(X_train_scaled).any())\n",
    "    print(\"Any NaNs in X_test_scaled?\", np.isnan(X_test_scaled).any())\n",
    "    \n",
    "    # Compute class weights for imbalance\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weights_dict = dict(enumerate(class_weights))\n",
    "    print(\"Class weights:\", class_weights_dict)\n",
    "    \n",
    "    # Build model with dropout for regularization\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        class_weight=class_weights_dict,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Predict probabilities on test set\n",
    "    y_pred_prob = model.predict(X_test_scaled).flatten()\n",
    "    \n",
    "    # Check for NaNs in predictions\n",
    "    print(\"Any NaNs in predicted probabilities?\", np.isnan(y_pred_prob).any())\n",
    "    \n",
    "    # Find best threshold by maximizing F1 score on test set\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_thresh = thresholds[best_idx]\n",
    "    \n",
    "    print(f\"Best threshold by F1 score on test set: {best_thresh:.4f}\")\n",
    "    print(f\"F1 score at best threshold: {f1_scores[best_idx]:.4f}\")\n",
    "    \n",
    "    # Compute final metrics using best threshold\n",
    "    y_pred_class = (y_pred_prob >= best_thresh).astype(int)\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_test, y_pred_prob))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred_class))\n",
    "    print(\"Brier Score:\", brier_score_loss(y_test, y_pred_prob))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"../data/processed/merged_panel_clean_data.csv\"\n",
    "    run_predictive_model(data_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
